{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\avcamp9\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf-last\\Lib\\site-packages\\keras_retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import pydicom\n",
    "import argparse\n",
    "import openpyxl\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import filters\n",
    "from skimage.measure import regionprops,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define example paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check all for correct input and output directories and names\n",
    "inputdatadir = 'D:\\\\syntheticCasesReady' \n",
    "outputdatadir = 'E:\\\\Preprocessed\\\\TrainCalcClusterSynthetic'\n",
    "input_file = '220414_CEmammo_classification_simulationsAstrid.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_patientfull = openpyxl.load_workbook(os.path.join(inputdatadir, input_file))\n",
    "sheet_train = wb_patientfull['AllCases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For training set\n",
    "list_train = []\n",
    "list_breast = []\n",
    "list_label = []\n",
    "for cell_obj in sheet_train['A'][1:] :\n",
    "    list_train.append(cell_obj.value)\n",
    "for cell_obj in sheet_train['B'][1:] :\n",
    "    list_breast.append(cell_obj.value)\n",
    "for cell_obj in sheet_train['F'][1:] :\n",
    "    list_label.append(cell_obj.value)\n",
    "  \n",
    "## For test set\n",
    "# list_train = []\n",
    "# list_breast = []\n",
    "# list_label = []\n",
    "# for cell_obj in sheet_test['A'][1:] :\n",
    "#     list_train.append(cell_obj.value)\n",
    "# for cell_obj in sheet_test['B'][1:] :\n",
    "#     list_breast.append(cell_obj.value)\n",
    "# for cell_obj in sheet_test['F'][1:] :\n",
    "#     list_label.append(cell_obj.value)\n",
    "\n",
    "# list_label[:] = ['0' if 'ben' in x else x for x in list_label]\n",
    "# list_label[:] = ['1' if 'mal' in x else x for x in list_label]\n",
    "\n",
    "list_label = ['0' if x=='benign' else x for x in list_label]\n",
    "list_label = ['1' if x=='malignant' else x for x in list_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_annotations = 'annotations_train_calccluster_synthetic.csv'\n",
    "annot_file = open(os.path.join(outputdatadir,output_annotations), 'w')\n",
    "csv_writer = csv.writer(annot_file)\n",
    "\n",
    "init_row = ['filename', 'x1', 'x2', 'y1', 'y2', 'labels', 'path_mask'] \n",
    "csv_writer.writerow(init_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6\n",
    "\n",
    "def resample_intensities(orig_img, bin_nr=256):\n",
    "    \n",
    "    v_count=0\n",
    "    img_list=[]\n",
    "    filtered = orig_img.copy()\n",
    "    \n",
    "    # Ensure all intensity values are positive\n",
    "    if np.min(orig_img.flatten()) < 0:\n",
    "        filtered += np.min(orig_img.flatten())\n",
    "        \n",
    "    # Compute resampling step based on min and max values\n",
    "    resampled = np.zeros_like(filtered)\n",
    "    max_val_img = np.max(filtered.flatten())\n",
    "    min_val_img = np.min(filtered.flatten())\n",
    "    step = (max_val_img-min_val_img) / bin_nr\n",
    "\n",
    "    # Resample intensity values\n",
    "    for st in np.arange(step+min_val_img, max_val_img+step, step):\n",
    "        resampled[(filtered<=st) & (filtered>=st-step)] = v_count\n",
    "        v_count += 1\n",
    "    \n",
    "    return np.array(resampled, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5\n",
    "\n",
    "def pre_processing_for_img(img):\n",
    "    temp_img = img.copy()\n",
    "    \n",
    "    # Compute thresholds from quantile\n",
    "    low_thr = np.quantile(temp_img[temp_img>0], 0.01)\n",
    "    high_thr = np.quantile(temp_img[temp_img>0], 0.99)\n",
    "    # Set values below low_thr or above high_thr to thr value respectively\n",
    "    temp_img[temp_img<low_thr] = low_thr\n",
    "    temp_img[temp_img>high_thr] = high_thr\n",
    "    \n",
    "    # If too many unique values, resample intensity values\n",
    "    if len(np.unique(temp_img[temp_img>0])) > 256:\n",
    "        temp_img_sampled = resample_intensities(temp_img[temp_img>0])\n",
    "        temp_img[temp_img>0] = temp_img_sampled    \n",
    "    # If not too many unique values, rescale based on min and max\n",
    "    else:\n",
    "        new_img = (temp_img-np.min(temp_img))/(np.max(temp_img)-np.min(temp_img)) \n",
    "        temp_img = (new_img*255).astype(np.uint8)   \n",
    "    return temp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4\n",
    "\n",
    "def crop_img(img_read_re, img_read_le):\n",
    "    \n",
    "#     # Apply otsu filter for foreground-background\n",
    "#     otsu = sitk.OtsuThresholdImageFilter()\n",
    "#     otsu_image = otsu.Execute(img_read_re)\n",
    "#     otsu_array = sitk.GetArrayFromImage(otsu_image)\n",
    "    # Alternative for dicom\n",
    "    temp_img_le_original = img_read_le.pixel_array\n",
    "    temp_img_re = img_read_re.pixel_array    \n",
    "\n",
    "    otsu_val = filters.threshold_otsu(temp_img_re)\n",
    "    otsu_array = temp_img_re < otsu_val\n",
    "    \n",
    "    # Find contours in image\n",
    "    invert_otsu = (np.ones(otsu_array.shape) - otsu_array).astype(np.uint8)\n",
    "    (contours,_) = cv2.findContours(invert_otsu, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    max_ctr = contours[0]\n",
    "    for ctr in contours:\n",
    "        if cv2.contourArea(ctr) > cv2.contourArea(max_ctr):\n",
    "            max_ctr = ctr\n",
    "    img_temp = np.zeros(invert_otsu.shape)\n",
    "    # Why ctr and not max_ctr? Something special about last ctr in contours? Ah, polygon is never used.\n",
    "    polygon = ctr\n",
    "    # Fill contour with ones\n",
    "    cv2.fillPoly(img_temp, [max_ctr], [1])\n",
    "    # Image where all outside contours are ones\n",
    "    otsu_array = np.ones(invert_otsu.shape) - img_temp\n",
    "        \n",
    "#     temp_img_re = sitk.GetArrayFromImage(img_read_re)    \n",
    "#     temp_img_le_original = sitk.GetArrayFromImage(img_read_le)\n",
    "        \n",
    "#     # Only img values not in otsu, which means indeed in contour\n",
    "#     temp_img_re = (np.ones((img_read_re.GetSize()[1],img_read_re.GetSize()[0])) - otsu_array)*temp_img_re\n",
    "#     temp_img_le = (np.ones((img_read_le.GetSize()[1],img_read_le.GetSize()[0])) - otsu_array)*temp_img_le_original\n",
    "    # Alternative for dicom\n",
    "    temp_img_re = (np.ones_like(temp_img_le_original) - otsu_array)*temp_img_re\n",
    "    temp_img_le = (np.ones_like(temp_img_le_original) - otsu_array)*temp_img_le_original\n",
    "    \n",
    "    # Get properties of all labeled regions, e.g. bounding box\n",
    "    props = regionprops(np.array(temp_img_re>0, np.uint8))\n",
    "    r0, c0, r1, c1 = props[0].bbox\n",
    "    \n",
    "    # Choose subarray in bounding box\n",
    "    temp_img_re = temp_img_re[r0:r1, c0:c1]   \n",
    "    # Apply preprocessing function\n",
    "    temp_img_re = pre_processing_for_img(temp_img_re)\n",
    "    \n",
    "    # Choose subarray in bounding box\n",
    "    temp_img_le = temp_img_le[r0:r1, c0:c1]\n",
    "    # Apply preprocessing function\n",
    "    temp_img_le = pre_processing_for_img(temp_img_le)\n",
    "    \n",
    "    return temp_img_re, temp_img_le, [r0,r1,c0,c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3\n",
    "\n",
    "def load_patient(path_input_recombined, path_input_low_energy):\n",
    "    \n",
    "    # Load images of patient\n",
    "    img_read_re = sitk.ReadImage(path_input_recombined)\n",
    "    img_read_le = sitk.ReadImage(path_input_low_energy)\n",
    "    \n",
    "    # Crop images\n",
    "    img_re, img_le, box_breast = crop_img(img_read_re, img_read_le)\n",
    "    \n",
    "    return img_le,img_re,box_breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3\n",
    "\n",
    "def load_patient_dicom(path_input_recombined, path_input_low_energy):\n",
    "    \n",
    "    # Load images of patient\n",
    "    img_read_re = pydicom.dcmread(path_input_recombined)\n",
    "    img_read_le = pydicom.dcmread(path_input_low_energy)\n",
    "    \n",
    "    # Crop images\n",
    "    img_re, img_le, box_breast = crop_img(img_read_re, img_read_le)\n",
    "\n",
    "    return img_le, img_re, box_breast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2\n",
    "\n",
    "def preprocessing(path_input_low_energy, path_input_recombined):\n",
    "    \n",
    "    # Set up 2 versions of CLAHE filter for histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(16,16))\n",
    "    clahe_recombined_2 = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(16,16)) \n",
    "\n",
    "    # Load preprocessed, cropped images of patient\n",
    "    img_le, img_re, box_breast = load_patient_dicom(path_input_recombined, path_input_low_energy)\n",
    "    \n",
    "    # Apply first version of CLAHE filter to low-energy image\n",
    "    new_img_le = (img_le-np.min(img_le)) / (np.max(img_le)-np.min(img_le)) \n",
    "    im_le = (new_img_le*255).astype(np.uint8)\n",
    "    x_le = clahe.apply(im_le).astype(np.uint8)\n",
    "    # Apply 2 versions of CLAHE filter to recombined image\n",
    "    new_img_re = (img_re-np.min(img_re)) / (np.max(img_re)-np.min(img_re)) \n",
    "    new_img_re = (new_img_re*255).astype(np.uint8)\n",
    "    x_re = clahe.apply(new_img_re).astype(np.uint8)\n",
    "    x_re_2 = clahe_recombined_2.apply(new_img_re).astype(np.uint8)\n",
    "\n",
    "    # Merge 3 images\n",
    "    temp_im_le = Image.fromarray(x_le)\n",
    "    temp_im_re = Image.fromarray(x_re)\n",
    "    temp_im_re_2 = Image.fromarray(x_re_2)\n",
    "    merged_img = Image.fromarray(cv2.merge((x_le,x_re,x_re_2)) )\n",
    "    # Convert to RGB\n",
    "    img_rgb = merged_img.convert(\"RGB\")\n",
    "    img_bgr = np.asarray(img_rgb)[:,:,::-1].copy()\n",
    "    \n",
    "    return img_bgr, box_breast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction: main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_classify_lesions_no_model(path_input_recombined, path_input_low_energy):\n",
    "    \n",
    "    img_bgr, box_breast = preprocessing(path_input_low_energy, path_input_recombined)\n",
    "            \n",
    "    return img_bgr, box_breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixeldict = {sitk.sitkUInt16: 'MET_USHORT'}\n",
    "\n",
    "reader = sitk.ImageFileReader()     # reader for the input .mha files\n",
    "reader.SetImageIO(\"MetaImageIO\")\n",
    "\n",
    "def loc_mask(path_input_struct, path_output_struct, bbox, lesion_label) :\n",
    "    \n",
    "    reader.SetFileName(path_input_struct)\n",
    "    mask_image = reader.Execute()\n",
    "    mask_array = sitk.GetArrayFromImage(mask_image).astype(np.uint16)\n",
    "    mask_array = mask_array[bbox[0]:bbox[1],bbox[2]:bbox[3]]\n",
    "    \n",
    "    mask_nz = np.nonzero(mask_array)\n",
    "    if len(mask_nz[0]) > 0 :\n",
    "        xmin = np.min(mask_nz[0])\n",
    "        xmax = np.max(mask_nz[0])\n",
    "        ymin = np.min(mask_nz[1])\n",
    "        ymax = np.max(mask_nz[1])\n",
    "\n",
    "        labeled_mask = label(mask_array, connectivity=2)\n",
    "        print('Unique mask labels', np.unique(labeled_mask))\n",
    "        if 'ben' in str(lesion_label) or '0' in str(lesion_label) :\n",
    "            labeled_mask[labeled_mask > 0] = 1\n",
    "        elif 'mal' in str(lesion_label) or '1' in str(lesion_label) :\n",
    "            labeled_mask[labeled_mask > 0] = 2\n",
    "#         matplotlib.image.imsave(path_output_struct, labeled_mask)\n",
    "        PIL_mask = Image.fromarray(np.uint8(labeled_mask))\n",
    "        PIL_mask.save(path_output_struct)        \n",
    "    \n",
    "        return xmin,xmax,ymin,ymax\n",
    "    \n",
    "    else :\n",
    "        return -1, -1, -1, -1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_mask_dicom(path_input_mask, path_output_mask, bbox, lesion_label) :\n",
    "    \n",
    "    mask = pydicom.dcmread(path_input_mask, force=True)\n",
    "    \n",
    "    mask_array = list(mask[0x4d4d,0x2a00].value)[-7330428:]\n",
    "    mask_array = np.array(mask_array)\n",
    "    mask_array = np.reshape(mask_array, (3062,2394))\n",
    "    mask_array = mask_array[bbox[0]:bbox[1],bbox[2]:bbox[3]]\n",
    "    \n",
    "    mask_nz = np.nonzero(mask_array)\n",
    "    if len(mask_nz[0]) > 0 :\n",
    "        xmin = np.min(mask_nz[0])\n",
    "        xmax = np.max(mask_nz[0])\n",
    "        ymin = np.min(mask_nz[1])\n",
    "        ymax = np.max(mask_nz[1])\n",
    "\n",
    "        labeled_mask = label(mask_array, connectivity=2)\n",
    "        print('Unique mask labels', np.unique(labeled_mask))\n",
    "        if 'ben' in str(lesion_label) or '0' in str(lesion_label) :\n",
    "            labeled_mask[labeled_mask > 0] = 1\n",
    "        elif 'mal' in str(lesion_label) or '1' in str(lesion_label) :\n",
    "            labeled_mask[labeled_mask > 0] = 2\n",
    "#         matplotlib.image.imsave(path_output_struct, labeled_mask)\n",
    "        PIL_mask = Image.fromarray(np.uint8(labeled_mask))\n",
    "        PIL_mask.save(path_output_mask)        \n",
    "    \n",
    "        return xmin,xmax,ymin,ymax\n",
    "    \n",
    "    else :\n",
    "        return -1, -1, -1, -1\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 190 MUMC_1801\n",
      "MUMC_1801_CC_L_LOW_ENERGY1.dcm MUMC_1801_CC_L_RECOMBINED1.dcm MUMC_1801_CC_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1801_MLO_L_LOW_ENERGY1.dcm MUMC_1801_MLO_L_RECOMBINED1.dcm MUMC_1801_MLO_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "1 191 MUMC_1142\n",
      "MUMC_1142_CC_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1142_CC_R_RECOMBINED1.dcm MUMC_1142_CC_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1142_MLO_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1142_MLO_R_RECOMBINED1.dcm MUMC_1142_MLO_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "2 192 MUMC_1126\n",
      "MUMC_1126_CC_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1126_CC_R_RECOMBINED1.dcm MUMC_1126_CC_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1126_MLO_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1126_MLO_R_RECOMBINED1.dcm MUMC_1126_MLO_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "3 193 MUMC_1071\n",
      "MUMC_1071_CC_L_LOW_ENERGY1_changedDataProvider.dcm MUMC_1071_CC_L_RECOMBINED1.dcm MUMC_1071_CC_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1071_MLO_L_LOW_ENERGY1_changedDataProvider.dcm MUMC_1071_MLO_L_RECOMBINED1.dcm MUMC_1071_MLO_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "4 194 MUMC_1031\n",
      "MUMC_1031_CC_L_LOW_ENERGY1_changedDataProvider.dcm MUMC_1031_CC_L_RECOMBINED1.dcm MUMC_1031_CC_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1031_MLO_L_LOW_ENERGY1_changedDataProvider.dcm MUMC_1031_MLO_L_RECOMBINED1.dcm MUMC_1031_MLO_L_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "5 195 MUMC_1024\n",
      "MUMC_1024_CC_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1024_CC_R_RECOMBINED1.dcm MUMC_1024_CC_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1024_MLO_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1024_MLO_R_RECOMBINED1.dcm MUMC_1024_MLO_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "6 196 MUMC_1010\n",
      "MUMC_1010_CC_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1010_CC_R_RECOMBINED1.dcm MUMC_1010_CC_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n",
      "MUMC_1010_MLO_R_LOW_ENERGY1_changedDataProvider.dcm MUMC_1010_MLO_R_RECOMBINED1.dcm MUMC_1010_MLO_R_LOW_ENERGY1_mask.dcm\n",
      "Unique mask labels [0 1]\n"
     ]
    }
   ],
   "source": [
    "startidx = 190\n",
    "\n",
    "for idx, patientdir in enumerate(list_train[startidx:]) :\n",
    "    \n",
    "    ## Patient and path\n",
    "    patient = patientdir[patientdir.index('MUMC'):patientdir.index('MUMC')+9]\n",
    "    breast = patient[-2:]             \n",
    "    print(idx, startidx+idx, patient)\n",
    "    \n",
    "    cc_dir = os.path.join(patientdir, 'CC')\n",
    "    mlo_dir = os.path.join(patientdir, 'MLO')\n",
    "    \n",
    "    ## CC\n",
    "    \n",
    "    # read input image and mask\n",
    "    for file in os.listdir(cc_dir) :\n",
    "        if 'LOW' in file and not 'mask' in file and '.dcm' in file :\n",
    "            le_name = file\n",
    "        elif 'REC' in file and not 'mask' in file and '.dcm' in file :\n",
    "            rc_name = file    \n",
    "        elif 'mask' in file and '.dcm' in file :\n",
    "            mask_name = file\n",
    "    print(le_name, rc_name, mask_name)\n",
    "    \n",
    "    # apply preprocessing to image\n",
    "    bg_cc, bbox_cc = detect_and_classify_lesions_no_model(os.path.join(cc_dir,le_name), os.path.join(cc_dir,rc_name))\n",
    "    \n",
    "    # find bounding box of mask and save if delineated\n",
    "    output_name_mask = os.path.join(outputdatadir, 'mask_to_png', patient+'_'+breast+'_CC.png')\n",
    "    x1_cc, x2_cc, y1_cc, y2_cc = loc_mask_dicom(os.path.join(cc_dir,mask_name), output_name_mask, bbox_cc, list_label[idx+startidx])\n",
    "    \n",
    "    # Only save if nonzero mask and thus delineated\n",
    "    if x1_cc > 0 :\n",
    "        \n",
    "        # save preprocessed image\n",
    "        im_cc = Image.fromarray(bg_cc)\n",
    "        output_name_image = os.path.join(outputdatadir, 'colored_to_jpg', patient+'_'+breast+'_CC.jpg')\n",
    "        im_cc.save(output_name_image)\n",
    "        \n",
    "        # save information in .csv file\n",
    "        cc_row = [output_name_image, x1_cc, x2_cc, y1_cc, y2_cc, list_label[idx+startidx], output_name_mask]\n",
    "        csv_writer.writerow(cc_row)\n",
    "    \n",
    "    ## MLO\n",
    "    for file in os.listdir(mlo_dir) :\n",
    "        if 'LOW' in file and not 'mask' in file and '.dcm' in file :\n",
    "            le_name = file\n",
    "        elif 'REC' in file and not 'mask' in file and '.dcm' in file :\n",
    "            rc_name = file  \n",
    "        elif 'mask' in file and '.dcm' in file :\n",
    "            mask_name = file            \n",
    "    print(le_name, rc_name, mask_name)\n",
    "    \n",
    "    # apply preprocessing to image\n",
    "    bg_mlo, bbox_mlo = detect_and_classify_lesions_no_model(os.path.join(mlo_dir,le_name), os.path.join(mlo_dir,rc_name))\n",
    "    \n",
    "    # find bounding box of mask and save if delineated\n",
    "    output_name_mask = os.path.join(outputdatadir, 'mask_to_png', patient+'_'+breast+'_MLO.png')\n",
    "    x1_mlo, x2_mlo, y1_mlo, y2_mlo = loc_mask_dicom(os.path.join(mlo_dir,mask_name), output_name_mask, bbox_mlo, list_label[idx+startidx])\n",
    "    \n",
    "    # Only save if nonzero mask and thus delineated\n",
    "    if x1_mlo > 0 :\n",
    "        \n",
    "        # save preprocessed image\n",
    "        im_mlo = Image.fromarray(bg_mlo)\n",
    "        output_name_image = os.path.join(outputdatadir, 'colored_to_jpg', patient+'_'+breast+'_MLO.jpg')\n",
    "        im_mlo.save(output_name_image)\n",
    "        \n",
    "        # save information in .csv file  \n",
    "        mlo_row = [output_name_image, x1_mlo, x2_mlo, y1_mlo, y2_mlo, list_label[idx+startidx], output_name_mask]\n",
    "        csv_writer.writerow(mlo_row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUMC_0286_XCCM_L_LOW_ENERGY1.dcm MUMC_0286_XCCM_L_RECOMBINED1.dcm MUMC_0286_XCCM_L_STRUCT1.mha\n",
      "Unique mask labels [0 1]\n"
     ]
    }
   ],
   "source": [
    "patient = 'MUMC_0286'\n",
    "\n",
    "cc_dir = os.path.join(inputdatadir, patient, 'L_XCCM')\n",
    "# mlo_dir = os.path.join(inputdatadir, patient, list_breast[idx+startidx]+'_MLO')\n",
    "\n",
    "## CC\n",
    "\n",
    "# read input image and mask\n",
    "for file in os.listdir(cc_dir) :\n",
    "    if 'LOW' in file and not 'mask' in file and '.dcm' in file :\n",
    "        le_name = file\n",
    "    elif 'REC' in file and not 'mask' in file and '.dcm' in file :\n",
    "        rc_name = file    \n",
    "    elif 'STRUCT' in file and '.mha' in file :\n",
    "        mask_name = file\n",
    "print(le_name, rc_name, mask_name)\n",
    "\n",
    "# apply preprocessing to image\n",
    "bg_cc, bbox_cc = detect_and_classify_lesions_no_model(os.path.join(cc_dir,le_name), os.path.join(cc_dir,rc_name))\n",
    "\n",
    "# find bounding box of mask and save if delineated\n",
    "output_name_mask = os.path.join(outputdatadir, 'mask_to_png', patient+'_'+list_breast[idx+startidx]+'_CC.png')\n",
    "x1_cc, x2_cc, y1_cc, y2_cc = loc_mask(os.path.join(cc_dir,mask_name), output_name_mask, bbox_cc, list_label[idx+startidx])\n",
    "\n",
    "# Only save if nonzero mask and thus delineated\n",
    "if x1_cc > 0 :\n",
    "\n",
    "    # save preprocessed image\n",
    "    im_cc = Image.fromarray(bg_cc)\n",
    "    output_name_image = os.path.join(outputdatadir, 'colored_to_jpg', patient+'_'+list_breast[idx+startidx]+'_CC.jpg')\n",
    "    im_cc.save(output_name_image)\n",
    "\n",
    "    # save information in .csv file\n",
    "    cc_row = [output_name_image, x1_cc, x2_cc, y1_cc, y2_cc, list_label[idx+startidx], output_name_mask]\n",
    "    csv_writer.writerow(cc_row)\n",
    "\n",
    "# ## MLO\n",
    "# for file in os.listdir(mlo_dir) :\n",
    "#     if 'LOW' in file and not 'mask' in file and '.dcm' in file :\n",
    "#         le_name = file\n",
    "#     elif 'REC' in file and not 'mask' in file and '.dcm' in file :\n",
    "#         rc_name = file  \n",
    "#     elif 'STRUCT' in file and '.mha' in file :\n",
    "#         mask_name = file            \n",
    "# print(le_name, rc_name, mask_name)\n",
    "\n",
    "# # apply preprocessing to image\n",
    "# bg_mlo, bbox_mlo = detect_and_classify_lesions_no_model(os.path.join(mlo_dir,le_name), os.path.join(mlo_dir,rc_name))\n",
    "\n",
    "# # find bounding box of mask and save if delineated\n",
    "# output_name_mask = os.path.join(outputdatadir, 'mask_to_png', patient+'_'+list_breast[idx+startidx]+'_MLO.png')\n",
    "# x1_mlo, x2_mlo, y1_mlo, y2_mlo = loc_mask(os.path.join(mlo_dir,mask_name), output_name_mask, bbox_mlo, list_label[idx+startidx])\n",
    "\n",
    "# # Only save if nonzero mask and thus delineated\n",
    "# if x1_mlo > 0 :\n",
    "\n",
    "#     # save preprocessed image\n",
    "#     im_mlo = Image.fromarray(bg_mlo)\n",
    "#     output_name_image = os.path.join(outputdatadir, 'colored_to_jpg', patient+'_'+list_breast[idx+startidx]+'_MLO.jpg')\n",
    "#     im_mlo.save(output_name_image)\n",
    "\n",
    "#     # save information in .csv file  \n",
    "#     mlo_row = [output_name_image, x1_mlo, x2_mlo, y1_mlo, y2_mlo, list_label[idx+startidx], output_name_mask]\n",
    "#     csv_writer.writerow(mlo_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = 'C:\\PhD\\syntheticCasesReady\\MUMC_0029_R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpatient = teststring[teststring.index('MUMC'):teststring.index('MUMC')+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MUMC_0029'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
